diff --git a/arch/arm/lib/Makefile b/arch/arm/lib/Makefile
index af72969820b4..d908b60bc4b2 100644
--- a/arch/arm/lib/Makefile
+++ b/arch/arm/lib/Makefile
@@ -42,6 +42,7 @@ endif
 
 lib-$(CONFIG_ARCH_RPC)		+= ecard.o io-acorn.o floppydma.o
 lib-$(CONFIG_ARCH_SHARK)	+= io-shark.o
+lib-$(CONFIG_ADAPTIVE_KSM)	+= memcmpksm.o
 
 $(obj)/csumpartialcopy.o:	$(obj)/csumpartialcopygeneric.S
 $(obj)/csumpartialcopyuser.o:	$(obj)/csumpartialcopygeneric.S
diff --git a/arch/arm/lib/memcmpksm.S b/arch/arm/lib/memcmpksm.S
new file mode 100644
index 000000000000..7fbcb02e7225
--- /dev/null
+++ b/arch/arm/lib/memcmpksm.S
@@ -0,0 +1,153 @@
+#include <linux/linkage.h>
+#include <asm/assembler.h>
+
+.text
+.arm
+.arch	armv7-a
+
+#define CACHE_LINE_SIZE 64
+
+ENTRY(page_memcmp)
+memcmp_ksm:
+	pld	[r0, #(CACHE_LINE_SIZE * 0)]
+	pld	[r1, #(CACHE_LINE_SIZE * 0)]
+	pld	[r0, #(CACHE_LINE_SIZE * 1)]
+	pld	[r1, #(CACHE_LINE_SIZE * 1)]
+
+	stmfd	sp!, {r4, lr}
+	mov	r3, r0
+
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+	subs	r0, r4, r0
+	popne	{r4, pc}
+	subs	r2, r2, #64
+loop:
+	pld	[r3, #(CACHE_LINE_SIZE * 2)]
+	pld	[r1, #(CACHE_LINE_SIZE * 2)]
+
+	ldr	r4, [r3], #4
+	ldr	r0, [r1], #4
+        eors        r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+        ldreq       r4, [r3], #4
+        ldreq       r0, [r1], #4
+        eoreqs     r0, r0, r4
+
+        bne         end_1
+        subs        r2, r2, #64
+        bne         loop
+
+	mov        r0, #0
+        ldmfd	sp!, {r4, lr}
+	bx	lr
+
+end_1:
+	sub         r3, r3, #4
+        sub         r0, r0, #4
+	sub        r0, r0, r3
+        ldmfd	sp!, {r4, lr}
+	bx	lr
+
+END(page_memcmp)
diff --git a/arch/arm64/lib/Makefile b/arch/arm64/lib/Makefile
index d98d3e39879e..2658d1a9df53 100644
--- a/arch/arm64/lib/Makefile
+++ b/arch/arm64/lib/Makefile
@@ -3,3 +3,5 @@ lib-y		:= bitops.o clear_user.o delay.o copy_from_user.o	\
 		   clear_page.o memchr.o memcpy.o memmove.o memset.o	\
 		   memcmp.o strcmp.o strncmp.o strlen.o strnlen.o	\
 		   strchr.o strrchr.o
+
+lib-$(CONFIG_ADAPTIVE_KSM) += memcmp_ksm.o pagesum_ksm.o
diff --git a/arch/arm64/lib/memcmp_ksm.S b/arch/arm64/lib/memcmp_ksm.S
new file mode 100644
index 000000000000..7b8441af2f15
--- /dev/null
+++ b/arch/arm64/lib/memcmp_ksm.S
@@ -0,0 +1,129 @@
+/*
+ * Copyright (C) 2013 ARM Ltd.
+ * Copyright (C) 2013 Linaro.
+ *
+ * This code is based on glibc cortex strings work originally authored by Linaro
+ * and re-licensed under GPLv2 for the Linux kernel. The original code can
+ * be found @
+ *
+ * http://bazaar.launchpad.net/~linaro-toolchain-dev/cortex-strings/trunk/
+ * files/head:/src/aarch64/
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/linkage.h>
+#include <asm/assembler.h>
+
+/*
+* compare memory areas(when two memory areas' offset are different,
+* alignment handled by the hardware)
+*
+* Parameters:
+*  x0 - const memory area 1 pointer
+*  x1 - const memory area 2 pointer
+*  x2 - the maximal compare byte length
+* Returns:
+*  x0 - a compare result, maybe less than, equal to, or greater than ZERO
+*/
+
+/* woosik.youm@samsung.com : modified for page compare */
+
+/* Parameters and result.  */
+src1	               .req   x0
+src2	               .req   x1
+limit	               .req   x2
+result              .req   x0
+
+/* Internal variables.  */
+data1               .req   x3
+data2               .req   x4
+data3               .req   x5
+data4               .req   x6
+diff                   .req   x7
+endloop           .req   x8
+pos                  .req   x9
+
+#define CACHE_LINE_SIZE 64
+
+ENTRY(page_memcmp)
+
+.Lloop_aligned:
+	prfm	pldl1strm, [src1, #(CACHE_LINE_SIZE * 1)]
+	prfm	pldl1strm, [src2, #(CACHE_LINE_SIZE * 1)]
+	prfm	pldl1strm, [src1, #(CACHE_LINE_SIZE * 2)]
+	prfm	pldl1strm, [src2, #(CACHE_LINE_SIZE * 2)]
+
+        ldp     data1, data2, [src1], #16
+        ldp     data3, data4, [src2], #16
+
+        eor   diff, data1, data3
+        cbnz diff, .Ldiff1
+        eor   diff, data2, data4
+        cbnz diff, .Ldiff2
+
+
+        ldp     data1, data2, [src1], #16
+        ldp     data3, data4, [src2], #16
+
+        eor   diff, data1, data3
+        cbnz diff, .Ldiff1
+        eor   diff, data2, data4
+        cbnz diff, .Ldiff2
+
+        ldp     data1, data2, [src1], #16
+        ldp     data3, data4, [src2], #16
+
+        eor   diff, data1, data3
+        cbnz diff, .Ldiff1
+        eor   diff, data2, data4
+        cbnz diff, .Ldiff2
+
+
+        ldp     data1, data2, [src1], #16
+        ldp     data3, data4, [src2], #16
+
+        eor   diff, data1, data3
+        cbnz diff, .Ldiff1
+        eor   diff, data2, data4
+        cbnz diff, .Ldiff2
+
+        sub limit, limit, #64
+	cbnz limit, .Lloop_aligned
+
+	mov	result, #0
+	ret
+
+.Ldiff1:
+CPU_LE( rev	diff, diff )
+CPU_LE( rev	data1, data1 )
+CPU_LE( rev	data3, data3 )
+	clz	pos, diff
+	lsl	data1, data1, pos
+	lsl	data3, data3, pos
+	lsr	data1, data1, #56
+	sub	result, data1, data3, lsr #56
+	ret
+
+.Ldiff2:
+CPU_LE( rev	diff, diff )
+CPU_LE( rev	data2, data2 )
+CPU_LE( rev	data4, data4 )
+	clz	pos, diff
+	lsl	data2, data2, pos
+	lsl	data4, data4, pos
+	lsr	data2, data2, #56
+	sub	result, data2, data4, lsr #56
+	ret
+
+ENDPROC(page_memcmp)
diff --git a/arch/arm64/lib/pagesum_ksm.S b/arch/arm64/lib/pagesum_ksm.S
new file mode 100644
index 000000000000..38e5fd154b53
--- /dev/null
+++ b/arch/arm64/lib/pagesum_ksm.S
@@ -0,0 +1,64 @@
+/* 2015-05-04 woosik.youm@samsung.com */
+
+#include <linux/linkage.h>
+#include <linux/const.h>
+#include <asm/assembler.h>
+#include <asm/page.h>
+
+#define CACHE_LINE_SIZE 64
+
+#define result		x0
+#define src		x1
+#define data1		x2
+#define data2		x3
+#define data3		x4
+#define data4		x5
+#define data5		x6
+#define data6		x7
+#define data7		x8
+#define data8		x9
+#define temp          x9
+
+ENTRY(calc_pagesum)
+
+	prfm	pldl1strm, [src, #(CACHE_LINE_SIZE * 1)]
+	prfm	pldl1strm, [src, #(CACHE_LINE_SIZE * 2)]
+        mov         src, x0
+        ldp     data1, data2, [src], #16
+        ldp     data3, data4, [src], #16
+        ldp     data5, data6, [src], #16
+        ldp     data7, data8, [src], #16
+
+        adds    result, data1, data2
+        adcs    result, result, data3
+        adcs    result, result, data4
+        adcs    result, result, data5
+        adcs    result, result, data6
+        adcs    result, result, data7
+        adcs    result, result, data8
+
+.loop_sum: // cache line size align
+	prfm  pldl1strm, [src, #(CACHE_LINE_SIZE * 2)]
+
+        ldp     data1, data2, [src], #16
+        ldp     data3, data4, [src], #16
+        ldp     data5, data6, [src], #16
+        ldp     data7, data8, [src], #16
+
+        adcs    result, data1, data2
+        adcs    result, result, data3
+        adcs    result, result, data4
+        adcs    result, result, data5
+        adcs    result, result, data6
+        adcs    result, result, data7
+        adcs    result, result, data8
+        and     temp, src, #(PAGE_SIZE-1)
+        cbnz    temp, .loop_sum
+        ret
+
+END(calc_pagesum)
+
+
+
+
+
diff --git a/drivers/staging/android/lowmemorykiller.c b/drivers/staging/android/lowmemorykiller.c
index c5d6fa7e353c..7d0e89104616 100644
--- a/drivers/staging/android/lowmemorykiller.c
+++ b/drivers/staging/android/lowmemorykiller.c
@@ -566,6 +566,19 @@ static void __exit lowmem_exit(void)
 	unregister_shrinker(&lowmem_shrinker);
 }
 
+#ifdef CONFIG_ADAPTIVE_KSM
+int get_minfree_high_value(void)
+{
+	int array_size = ARRAY_SIZE(lowmem_adj);
+	if (lowmem_adj_size < array_size)
+		array_size = lowmem_adj_size;
+	if (lowmem_minfree_size < array_size)
+		array_size = lowmem_minfree_size;
+
+	return lowmem_minfree[array_size-1];
+}
+EXPORT_SYMBOL(get_minfree_high_value);
+#endif
 #ifdef CONFIG_ANDROID_LOW_MEMORY_KILLER_AUTODETECT_OOM_ADJ_VALUES
 static short lowmem_oom_adj_to_oom_score_adj(short oom_adj)
 {
diff --git a/mm/Kconfig b/mm/Kconfig
index 312041563f3f..bed025239374 100644
--- a/mm/Kconfig
+++ b/mm/Kconfig
@@ -316,6 +316,18 @@ config KSM
 	  until a program has madvised that an area is MADV_MERGEABLE, and
 	  root has set /sys/kernel/mm/ksm/run to 1 (if CONFIG_SYSFS is set).
 
+config ADAPTIVE_KSM
+	bool "Enable Adaptive KSM"
+	depends on KSM
+	help
+	  Enable Adaptive KSM
+
+config AKSM_FB_NOTIFY
+	bool "Use FB Notify for aksm suspend"
+	depends on ADAPTIVE_KSM
+	help
+	  Use FB Notify for aksm suspend
+
 config DEFAULT_MMAP_MIN_ADDR
         int "Low address space to protect from user allocation"
 	depends on MMU
diff --git a/mm/ksm.c b/mm/ksm.c
index 11f6293cf38a..3b84ca2cebd3 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -50,6 +50,63 @@
 #define DO_NUMA(x)	do { } while (0)
 #endif
 
+#ifdef CONFIG_ADAPTIVE_KSM
+#include <linux/pm_runtime.h>
+#include <linux/platform_device.h>
+#include <asm/checksum.h>
+#include <linux/suspend.h>
+#include <linux/fb.h>
+
+#define AKSM_FULL_SCAN_NONE		0
+#define AKSM_FULL_SCAN_START		1
+#define AKSM_FULL_SCAN_END		2
+
+#define AKSM_MEM_NORMAL_ZONE		1
+#define AKSM_MEM_WARN_ZONE		2
+#define AKSM_MEM_CRITICAL_ZONE		3
+#define AKSM_MEM_BOOT_ZONE		4
+
+#define AKSM_PAGES_TO_SCAN		80
+#define AKSM_CHECK_MEM_INTERVAL         8000
+
+#define AKSM_PAGES_TO_SCAN_BOOT	        200
+#define AKSM_CHECK_MEM_INTERVAL_BOOT    6000
+
+#define AKSM_PAGES_TO_SCAN_WARN	        50
+#define AKSM_CHECK_MEM_INTERVAL_WARN    4000
+
+#define AKSM_PAGES_TO_SCAN_CRITICAL     60
+#define AKSM_CHECK_MEM_INTERVAL_CRITICAL        2000
+
+#define AKSM_SLEEP_TIME_PER_SCAN_IDLE          500
+#define AKSM_SLEEP_TIME_PER_SCAN_NON_IDLE	1
+
+#define AKSM_FULL_SCAN_TRY_BOOT                 4
+
+#define print_aksm(x,a...)    if(AKSM_Klog_enabled) printk(x,##a);
+
+static unsigned int AKSM_Klog_enabled = 0;
+static unsigned int AKSM_mem_status = 0;
+static unsigned int AKSM_full_scan_staus = 0;
+static unsigned int AKSM_early_suspended = 0;
+static unsigned int AKSM_onBoot = 1;
+static unsigned int AKSM_sleep_time_per_scan = 1;
+
+static unsigned int aksm_minfree_warn = 30720;	//default value 
+static unsigned int aksm_minfree_critical = 10240;	//default value
+
+#ifdef AKSM_DEBUG
+static unsigned int aksm_scan_num;
+static unsigned int aksm_scan_skip_num;
+#endif
+
+unsigned int check_mem_status(void);
+extern int get_minfree_high_value(void);
+void set_AKSM_level(void);
+extern int page_memcmp(const void *, const void *, __kernel_size_t);
+extern u64 calc_pagesum(const void *);
+#endif // CONFIG_ADAPTIVE_KSM
+
 /*
  * A few notes about the KSM scanning process,
  * to make it easier to understand the data structures below:
@@ -169,7 +226,11 @@ struct rmap_item {
 	};
 	struct mm_struct *mm;
 	unsigned long address;		/* + low bits used for flags below */
+#if defined(CONFIG_ADAPTIVE_KSM) && defined(CONFIG_ARM64)
+	unsigned long oldchecksum;	/* when unstable */
+#else
 	unsigned int oldchecksum;	/* when unstable */
+#endif
 	union {
 		struct rb_node node;	/* when node of unstable tree */
 		struct {		/* when listed from stable tree */
@@ -843,6 +904,16 @@ error:
 }
 #endif /* CONFIG_SYSFS */
 
+#if defined(CONFIG_ADAPTIVE_KSM) && defined(CONFIG_ARM64)
+static u64 calc_checksum(struct page *page)
+{
+	u64 checksum;
+	void *addr = kmap_atomic(page);
+	checksum = calc_pagesum(addr);
+	kunmap_atomic(addr);
+	return checksum;
+}
+#else
 static u32 calc_checksum(struct page *page)
 {
 	u32 checksum;
@@ -851,6 +922,7 @@ static u32 calc_checksum(struct page *page)
 	kunmap_atomic(addr);
 	return checksum;
 }
+#endif
 
 static int memcmp_pages(struct page *page1, struct page *page2)
 {
@@ -859,7 +931,11 @@ static int memcmp_pages(struct page *page1, struct page *page2)
 
 	addr1 = kmap_atomic(page1);
 	addr2 = kmap_atomic(page2);
+#ifdef CONFIG_ADAPTIVE_KSM
+	ret = page_memcmp((long *)addr1, (long *)addr2, PAGE_SIZE);
+#else
 	ret = memcmp(addr1, addr2, PAGE_SIZE);
+#endif
 	kunmap_atomic(addr2);
 	kunmap_atomic(addr1);
 	return ret;
@@ -1358,6 +1434,18 @@ struct rmap_item *unstable_tree_search_insert(struct rmap_item *rmap_item,
 
 		cond_resched();
 		tree_rmap_item = rb_entry(*new, struct rmap_item, node);
+#ifdef CONFIG_ADAPTIVE_KSM
+		parent = *new;
+		if ((rmap_item->address & PAGE_MASK) <
+		    (tree_rmap_item->address & PAGE_MASK)) {
+			new = &parent->rb_left;
+			continue;
+		} else if ((rmap_item->address & PAGE_MASK) >
+			   (tree_rmap_item->address & PAGE_MASK)) {
+			new = &parent->rb_right;
+			continue;
+		}
+#endif
 		tree_page = get_mergeable_page(tree_rmap_item);
 		if (IS_ERR_OR_NULL(tree_page))
 			return NULL;
@@ -1437,7 +1525,11 @@ static void cmp_and_merge_page(struct page *page, struct rmap_item *rmap_item)
 	struct page *tree_page = NULL;
 	struct stable_node *stable_node;
 	struct page *kpage;
+#if defined(CONFIG_ADAPTIVE_KSM) && defined(CONFIG_ARM64)
+	unsigned long checksum;
+#else
 	unsigned int checksum;
+#endif
 	int err;
 
 	stable_node = page_stable_node(page);
@@ -1702,9 +1794,161 @@ next_mm:
 		goto next_mm;
 
 	ksm_scan.seqnr++;
+#ifdef CONFIG_ADAPTIVE_KSM
+	if ((AKSM_onBoot) && (ksm_scan.seqnr == AKSM_FULL_SCAN_TRY_BOOT)) {
+		AKSM_onBoot = 0;
+		set_AKSM_level();
+	}
+	AKSM_full_scan_staus = AKSM_FULL_SCAN_END;
+#endif
 	return NULL;
 }
 
+#ifdef CONFIG_ADAPTIVE_KSM
+#ifdef CONFIG_AKSM_PLATFORM_DEVICE
+static int  AKSM_suspend(struct device *dev)
+{
+        if(AKSM_early_suspended)
+                return 0;
+	AKSM_early_suspended=1;
+	printk("AKSM_early_suspended in\n");
+        return 0;
+}
+
+static int AKSM_resume(struct device *dev)
+{
+        if(!AKSM_early_suspended)
+                return 0;
+	AKSM_early_suspended=0;
+	printk("AKSM_early_suspended out\n");
+        return 0;
+}
+
+const struct dev_pm_ops aksm_pm_ops = {
+        .suspend = AKSM_suspend,
+        .resume = AKSM_resume,
+        .runtime_suspend = AKSM_suspend,
+        .runtime_resume = AKSM_resume,
+};
+
+static struct platform_driver aksm_drvier = {
+        .driver         = {
+                .name   = "aksm",
+                .owner  = THIS_MODULE,
+                .pm     = &aksm_pm_ops,
+        },
+};
+static struct platform_device aksm_device = {
+        .name   = "aksm",
+        .id     = -1,
+};
+#elif defined CONFIG_AKSM_PM_NOTIFY
+static int aksm_pm_notify(struct notifier_block *nb,
+				unsigned long event,
+				void *data)
+{
+	printk("aksm_pm_notify : %lu \n",event);
+	if(event == PM_SUSPEND_PREPARE)
+	{
+		AKSM_early_suspended=1;
+		printk("AKSM_early_suspended in\n");
+	}
+	else if(event == PM_POST_SUSPEND)
+	{
+		AKSM_early_suspended=0;
+		printk("AKSM_early_suspended out\n");
+	}
+	return 0;
+}
+
+static struct notifier_block aksm_pm_notifier = {
+	.notifier_call = aksm_pm_notify,
+};
+#elif defined CONFIG_AKSM_FB_NOTIFY
+static int aksm_fb_notify(struct notifier_block *nb,
+				unsigned long event,
+				void *data)
+{
+	if(ksm_run == KSM_RUN_STOP)
+		return 0;
+
+	if(event == FB_EARLY_EVENT_BLANK)
+	{
+		if(AKSM_early_suspended)
+			AKSM_early_suspended=0;
+		else
+			AKSM_early_suspended=1;
+		printk("AKSM_early_suspended %d\n", AKSM_early_suspended);
+	}
+
+	return 0;
+}
+
+static struct notifier_block aksm_fb_notifier = {
+	.notifier_call = aksm_fb_notify,
+};
+
+#endif
+
+void set_AKSM_level(void)
+{
+	aksm_minfree_critical =
+	    get_minfree_high_value() + global_page_state(NR_SHMEM) +
+	    total_swapcache_pages();
+	aksm_minfree_warn = aksm_minfree_critical * 2;
+}
+
+unsigned int check_mem_status(void)
+{
+
+	unsigned int available_mem =
+	    global_page_state(NR_FREE_PAGES) - totalreserve_pages +
+	    global_page_state(NR_FILE_PAGES)
+	    - global_page_state(NR_SHMEM)
+	    - total_swapcache_pages();	/* pages */
+
+	if (AKSM_onBoot) {
+		set_user_nice(current, 5);
+		ksm_thread_pages_to_scan = AKSM_PAGES_TO_SCAN_BOOT;
+		ksm_thread_sleep_millisecs = AKSM_CHECK_MEM_INTERVAL_BOOT;
+		AKSM_mem_status = AKSM_MEM_BOOT_ZONE;
+		AKSM_sleep_time_per_scan = AKSM_SLEEP_TIME_PER_SCAN_NON_IDLE;
+	} else {
+		if (available_mem < aksm_minfree_critical) {
+			set_user_nice(current, 13);
+			ksm_thread_pages_to_scan = AKSM_PAGES_TO_SCAN_CRITICAL;
+			ksm_thread_sleep_millisecs =
+			    AKSM_CHECK_MEM_INTERVAL_CRITICAL;
+			AKSM_mem_status = AKSM_MEM_CRITICAL_ZONE;
+			AKSM_sleep_time_per_scan =
+			    AKSM_SLEEP_TIME_PER_SCAN_NON_IDLE;
+		} else if (available_mem < aksm_minfree_warn) {
+			set_user_nice(current, 7);
+			ksm_thread_pages_to_scan = AKSM_PAGES_TO_SCAN_WARN;
+			ksm_thread_sleep_millisecs =
+			    AKSM_CHECK_MEM_INTERVAL_WARN;
+			AKSM_mem_status = AKSM_MEM_WARN_ZONE;
+			AKSM_sleep_time_per_scan =
+			    AKSM_SLEEP_TIME_PER_SCAN_NON_IDLE;
+		} else {
+			set_user_nice(current, 19);
+			ksm_thread_pages_to_scan = AKSM_PAGES_TO_SCAN;
+			ksm_thread_sleep_millisecs = AKSM_CHECK_MEM_INTERVAL;
+			AKSM_mem_status = AKSM_MEM_NORMAL_ZONE;
+			AKSM_sleep_time_per_scan =
+			    AKSM_SLEEP_TIME_PER_SCAN_IDLE;
+		}
+	}
+
+	if (AKSM_full_scan_staus == AKSM_FULL_SCAN_NONE)
+		print_aksm("available_mem : %d, AKSM_mem_status : %d\n",
+			   available_mem, AKSM_mem_status);
+
+	return AKSM_mem_status;
+
+}
+
+#endif
 /**
  * ksm_do_scan  - the ksm scanner main worker function.
  * @scan_npages - number of pages we want to scan before we return.
@@ -1770,6 +2014,48 @@ static int ksm_scan_thread(void *nothing)
 	set_user_nice(current, 5);
 
 	while (!kthread_should_stop()) {
+#ifdef CONFIG_ADAPTIVE_KSM
+		if (check_mem_status())
+			if ((ksmd_should_run()) && (!AKSM_early_suspended)) {
+				print_aksm
+				    ("Full Scan Started, AKSM_mem_status : %d\n",
+				     AKSM_mem_status);
+				AKSM_full_scan_staus = AKSM_FULL_SCAN_START;
+			}
+
+		while (AKSM_full_scan_staus) {
+			mutex_lock(&ksm_thread_mutex);
+			wait_while_offlining();
+			ksm_do_scan(ksm_thread_pages_to_scan);
+			mutex_unlock(&ksm_thread_mutex);
+			check_mem_status();
+
+			if ((AKSM_early_suspended)
+			    || (AKSM_full_scan_staus == AKSM_FULL_SCAN_END)) {
+				print_aksm
+				    ("Full Scan Ended or AKSM_early_suspended : %d, AKSM_full_scan_staus : %d, AKSM_mem_status : %d\n",
+				     AKSM_early_suspended, AKSM_full_scan_staus,
+				     AKSM_mem_status);
+				AKSM_full_scan_staus = AKSM_FULL_SCAN_NONE;
+				break;
+			}
+			// try_to_freeze();
+			schedule_timeout_interruptible(msecs_to_jiffies
+						       (AKSM_sleep_time_per_scan));
+		}
+
+		print_aksm
+		    ("ksm_pages_shared : %ld, ksm_pages_sharing : %ld, ksm_pages_unshared : %ld\n",
+		     ksm_pages_shared, ksm_pages_sharing, ksm_pages_unshared);
+		try_to_freeze();
+		if (use_deferred_timer)
+			deferred_schedule_timeout(
+			msecs_to_jiffies(ksm_thread_sleep_millisecs));
+		else
+			schedule_timeout_interruptible(
+			msecs_to_jiffies(ksm_thread_sleep_millisecs));
+
+#else //CONFIG_ADAPTIVE_KSM
 		mutex_lock(&ksm_thread_mutex);
 		wait_while_offlining();
 		if (ksmd_should_run())
@@ -1789,6 +2075,7 @@ static int ksm_scan_thread(void *nothing)
 			wait_event_freezable(ksm_thread_wait,
 				ksmd_should_run() || kthread_should_stop());
 		}
+#endif
 	}
 	return 0;
 }
@@ -2262,7 +2549,9 @@ static ssize_t sleep_millisecs_store(struct kobject *kobj,
 	if (err || msecs > UINT_MAX)
 		return -EINVAL;
 
+#ifndef CONFIG_ADAPTIVE_KSM
 	ksm_thread_sleep_millisecs = msecs;
+#endif
 
 	return count;
 }
@@ -2285,7 +2574,9 @@ static ssize_t pages_to_scan_store(struct kobject *kobj,
 	if (err || nr_pages > UINT_MAX)
 		return -EINVAL;
 
+#ifndef CONFIG_ADAPTIVE_KSM
 	ksm_thread_pages_to_scan = nr_pages;
+#endif
 
 	return count;
 }
@@ -2462,6 +2753,83 @@ static ssize_t full_scans_show(struct kobject *kobj,
 }
 KSM_ATTR_RO(full_scans);
 
+#ifdef CONFIG_ADAPTIVE_KSM
+static ssize_t aksm_minfree_critical_store(struct kobject *kobj,
+					   struct kobj_attribute *attr,
+					   const char *buf, size_t count)
+{
+	int err;
+	unsigned long aksm_minfree;
+
+	err = strict_strtoul(buf, 10, &aksm_minfree);
+	if (err || aksm_minfree > UINT_MAX)
+		return -EINVAL;
+
+	aksm_minfree_critical = aksm_minfree;
+
+	return count;
+}
+
+static ssize_t aksm_minfree_critical_show(struct kobject *kobj,
+					  struct kobj_attribute *attr,
+					  char *buf)
+{
+
+	return sprintf(buf, "%u\n", aksm_minfree_critical);
+}
+
+KSM_ATTR(aksm_minfree_critical);
+
+static ssize_t aksm_minfree_warn_store(struct kobject *kobj,
+				       struct kobj_attribute *attr,
+				       const char *buf, size_t count)
+{
+	int err;
+	unsigned long aksm_minfree;
+
+	err = strict_strtoul(buf, 10, &aksm_minfree);
+	if (err || aksm_minfree > UINT_MAX)
+		return -EINVAL;
+
+	aksm_minfree_warn = aksm_minfree;
+
+	return count;
+}
+
+static ssize_t aksm_minfree_warn_show(struct kobject *kobj,
+				      struct kobj_attribute *attr, char *buf)
+{
+
+	return sprintf(buf, "%u\n", aksm_minfree_warn);
+}
+
+KSM_ATTR(aksm_minfree_warn);
+
+static ssize_t AKSM_Klog_enable_store(struct kobject *kobj,
+				      struct kobj_attribute *attr,
+				      const char *buf, size_t count)
+{
+	int err;
+	unsigned long enableklog;
+
+	err = strict_strtoul(buf, 10, &enableklog);
+	if (err || enableklog > UINT_MAX)
+		return -EINVAL;
+
+	AKSM_Klog_enabled = enableklog;
+
+	return count;
+}
+
+static ssize_t AKSM_Klog_enable_show(struct kobject *kobj,
+				     struct kobj_attribute *attr, char *buf)
+{
+
+	return sprintf(buf, "AKSM_Klog_enabled : %d\n", AKSM_Klog_enabled);
+}
+
+KSM_ATTR(AKSM_Klog_enable);
+#endif
 static struct attribute *ksm_attrs[] = {
 	&sleep_millisecs_attr.attr,
 	&pages_to_scan_attr.attr,
@@ -2475,6 +2843,11 @@ static struct attribute *ksm_attrs[] = {
 #ifdef CONFIG_NUMA
 	&merge_across_nodes_attr.attr,
 #endif
+#ifdef CONFIG_ADAPTIVE_KSM
+	&aksm_minfree_critical_attr.attr,
+	&aksm_minfree_warn_attr.attr,
+	&AKSM_Klog_enable_attr.attr,
+#endif
 	NULL,
 };
 
@@ -2492,6 +2865,19 @@ static int __init ksm_init(void)
 	err = ksm_slab_init();
 	if (err)
 		goto out;
+#ifdef CONFIG_ADAPTIVE_KSM
+	ksm_thread_pages_to_scan = AKSM_PAGES_TO_SCAN;
+	ksm_thread_sleep_millisecs = AKSM_CHECK_MEM_INTERVAL;
+#ifdef CONFIG_AKSM_PLATFORM_DEVICE
+	platform_device_register(&aksm_device);
+	platform_driver_register(&aksm_drvier);
+	pm_runtime_enable(&aksm_device.dev);
+#elif defined CONFIG_AKSM_PM_NOTIFY
+	register_pm_notifier(&aksm_pm_notifier);
+#elif defined CONFIG_AKSM_FB_NOTIFY
+	fb_register_client(&aksm_fb_notifier);
+#endif
+#endif
 
 	ksm_thread = kthread_run(ksm_scan_thread, NULL, "ksmd");
 	if (IS_ERR(ksm_thread)) {
